{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using a Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../train.csv\")\n",
    "val = pd.read_csv(\"../val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=3000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = train.iloc[:,2]\n",
    "train_labels = train.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vec (arr): \n",
    "    one = [1, 0, 0, 0, 0]\n",
    "    two = [0, 1, 0, 0, 0]\n",
    "    three = [0, 0, 1, 0, 0]\n",
    "    four = [0, 0, 0, 1, 0]\n",
    "    five = [0, 0, 0, 0, 1]\n",
    "    train_labels = []\n",
    "    \n",
    "    for i in range (0, arr.shape[0]): \n",
    "        x = arr.iloc[i]\n",
    "        if x <= 0.2: \n",
    "            value = one\n",
    "        elif x <= 0.4: \n",
    "            value = two\n",
    "        elif x <= 0.6: \n",
    "            value = three\n",
    "        elif x <= 0.8: \n",
    "            value = four \n",
    "        elif x <= 1:\n",
    "            value = five\n",
    "        else: \n",
    "            print(x)\n",
    "            print(arr.iloc[x])\n",
    "            assert(1 == 2)\n",
    "        \n",
    "        train_labels.append(value)\n",
    "    \n",
    "    train_labels = pd.DataFrame(train_labels)\n",
    "    return train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191385, 3000)\n",
      "(191385, 5)\n"
     ]
    }
   ],
   "source": [
    "train_labels = to_vec(train_labels)\n",
    "train_features = vectorizer.fit_transform(train_words)\n",
    "print(train_features.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23923, 5)\n",
      "(23923, 3000)\n"
     ]
    }
   ],
   "source": [
    "val_words = val.iloc[:,2]\n",
    "val_labels = val.iloc[:,1]\n",
    "val_labels = to_vec(val_labels)\n",
    "val_features = vectorizer.transform(val_words)\n",
    "print(val_labels.shape)\n",
    "print(val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "train_features = preprocessing.normalize(train_features)\n",
    "val_features = preprocessing.normalize(val_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = MLPClassifier(verbose=True, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.93332744\n",
      "Iteration 2, loss = 1.64101884\n",
      "Iteration 3, loss = 1.59267137\n",
      "Iteration 4, loss = 1.55789583\n",
      "Iteration 5, loss = 1.52725970\n",
      "Iteration 6, loss = 1.49924568\n",
      "Iteration 7, loss = 1.47343806\n",
      "Iteration 8, loss = 1.44925553\n",
      "Iteration 9, loss = 1.42693463\n",
      "Iteration 10, loss = 1.40537766\n",
      "Iteration 11, loss = 1.38477637\n",
      "Iteration 12, loss = 1.36526140\n",
      "Iteration 13, loss = 1.34641358\n",
      "Iteration 14, loss = 1.32850074\n",
      "Iteration 15, loss = 1.31095700\n",
      "Iteration 16, loss = 1.29422281\n",
      "Iteration 17, loss = 1.27860788\n",
      "Iteration 18, loss = 1.26356013\n",
      "Iteration 19, loss = 1.24867858\n",
      "Iteration 20, loss = 1.23465446\n",
      "Iteration 21, loss = 1.22146103\n",
      "Iteration 22, loss = 1.20920264\n",
      "Iteration 23, loss = 1.19712781\n",
      "Iteration 24, loss = 1.18579242\n",
      "Iteration 25, loss = 1.17494915\n",
      "Iteration 26, loss = 1.16416618\n",
      "Iteration 27, loss = 1.15426712\n",
      "Iteration 28, loss = 1.14443509\n",
      "Iteration 29, loss = 1.13582294\n",
      "Iteration 30, loss = 1.12655993\n",
      "Iteration 31, loss = 1.11815276\n",
      "Iteration 32, loss = 1.11019470\n",
      "Iteration 33, loss = 1.10228577\n",
      "Iteration 34, loss = 1.09467164\n",
      "Iteration 35, loss = 1.08741649\n",
      "Iteration 36, loss = 1.08078461\n",
      "Iteration 37, loss = 1.07378130\n",
      "Iteration 38, loss = 1.06691821\n",
      "Iteration 39, loss = 1.06054301\n",
      "Iteration 40, loss = 1.05475216\n",
      "Iteration 41, loss = 1.04916983\n",
      "Iteration 42, loss = 1.04293695\n",
      "Iteration 43, loss = 1.03761250\n",
      "Iteration 44, loss = 1.03202187\n",
      "Iteration 45, loss = 1.02648537\n",
      "Iteration 46, loss = 1.02178885\n",
      "Iteration 47, loss = 1.01702800\n",
      "Iteration 48, loss = 1.01243406\n",
      "Iteration 49, loss = 1.00747498\n",
      "Iteration 50, loss = 1.00242944\n",
      "Iteration 51, loss = 0.99836729\n",
      "Iteration 52, loss = 0.99401436\n",
      "Iteration 53, loss = 0.99040817\n",
      "Iteration 54, loss = 0.98625781\n",
      "Iteration 55, loss = 0.98197726\n",
      "Iteration 56, loss = 0.97843433\n",
      "Iteration 57, loss = 0.97492961\n",
      "Iteration 58, loss = 0.97072144\n",
      "Iteration 59, loss = 0.96737304\n",
      "Iteration 60, loss = 0.96387240\n",
      "Iteration 61, loss = 0.96021874\n",
      "Iteration 62, loss = 0.95694609\n",
      "Iteration 63, loss = 0.95404407\n",
      "Iteration 64, loss = 0.95049457\n",
      "Iteration 65, loss = 0.94754471\n",
      "Iteration 66, loss = 0.94467285\n",
      "Iteration 67, loss = 0.94173499\n",
      "Iteration 68, loss = 0.93897965\n",
      "Iteration 69, loss = 0.93615903\n",
      "Iteration 70, loss = 0.93337237\n",
      "Iteration 71, loss = 0.93067005\n",
      "Iteration 72, loss = 0.92825653\n",
      "Iteration 73, loss = 0.92556293\n",
      "Iteration 74, loss = 0.92303771\n",
      "Iteration 75, loss = 0.92119148\n",
      "Iteration 76, loss = 0.91804550\n",
      "Iteration 77, loss = 0.91562023\n",
      "Iteration 78, loss = 0.91375081\n",
      "Iteration 79, loss = 0.91131325\n",
      "Iteration 80, loss = 0.90966841\n",
      "Iteration 81, loss = 0.90665101\n",
      "Iteration 82, loss = 0.90494980\n",
      "Iteration 83, loss = 0.90290736\n",
      "Iteration 84, loss = 0.90163385\n",
      "Iteration 85, loss = 0.89811169\n",
      "Iteration 86, loss = 0.89793492\n",
      "Iteration 87, loss = 0.89480625\n",
      "Iteration 88, loss = 0.89283121\n",
      "Iteration 89, loss = 0.89108175\n",
      "Iteration 90, loss = 0.89040086\n",
      "Iteration 91, loss = 0.88803224\n",
      "Iteration 92, loss = 0.88609725\n",
      "Iteration 93, loss = 0.88412090\n",
      "Iteration 94, loss = 0.88247293\n",
      "Iteration 95, loss = 0.88109720\n",
      "Iteration 96, loss = 0.87900649\n",
      "Iteration 97, loss = 0.87786340\n",
      "Iteration 98, loss = 0.87655378\n",
      "Iteration 99, loss = 0.87444824\n",
      "Iteration 100, loss = 0.87317705\n",
      "Iteration 101, loss = 0.87218272\n",
      "Iteration 102, loss = 0.87010325\n",
      "Iteration 103, loss = 0.86935098\n",
      "Iteration 104, loss = 0.86729454\n",
      "Iteration 105, loss = 0.86576962\n",
      "Iteration 106, loss = 0.86486533\n",
      "Iteration 107, loss = 0.86311863\n",
      "Iteration 108, loss = 0.86267054\n",
      "Iteration 109, loss = 0.86052410\n",
      "Iteration 110, loss = 0.85953372\n",
      "Iteration 111, loss = 0.85797106\n",
      "Iteration 112, loss = 0.85634910\n",
      "Iteration 113, loss = 0.85512179\n",
      "Iteration 114, loss = 0.85430786\n",
      "Iteration 115, loss = 0.85288189\n",
      "Iteration 116, loss = 0.85216731\n",
      "Iteration 117, loss = 0.85142500\n",
      "Iteration 118, loss = 0.84969082\n",
      "Iteration 119, loss = 0.84831869\n",
      "Iteration 120, loss = 0.84722336\n",
      "Iteration 121, loss = 0.84616182\n",
      "Iteration 122, loss = 0.84482631\n",
      "Iteration 123, loss = 0.84405165\n",
      "Iteration 124, loss = 0.84331338\n",
      "Iteration 125, loss = 0.84211080\n",
      "Iteration 126, loss = 0.84190749\n",
      "Iteration 127, loss = 0.84020848\n",
      "Iteration 128, loss = 0.83875934\n",
      "Iteration 129, loss = 0.83860560\n",
      "Iteration 130, loss = 0.83749115\n",
      "Iteration 131, loss = 0.83649736\n",
      "Iteration 132, loss = 0.83588901\n",
      "Iteration 133, loss = 0.83409180\n",
      "Iteration 134, loss = 0.83376079\n",
      "Iteration 135, loss = 0.83240130\n",
      "Iteration 136, loss = 0.83154743\n",
      "Iteration 137, loss = 0.83110956\n",
      "Iteration 138, loss = 0.83012848\n",
      "Iteration 139, loss = 0.82935918\n",
      "Iteration 140, loss = 0.82797614\n",
      "Iteration 141, loss = 0.82805917\n",
      "Iteration 142, loss = 0.82658976\n",
      "Iteration 143, loss = 0.82608860\n",
      "Iteration 144, loss = 0.82547713\n",
      "Iteration 145, loss = 0.82341806\n",
      "Iteration 146, loss = 0.82391671\n",
      "Iteration 147, loss = 0.82304851\n",
      "Iteration 148, loss = 0.82157670\n",
      "Iteration 149, loss = 0.82139698\n",
      "Iteration 150, loss = 0.82053610\n",
      "Iteration 151, loss = 0.81989287\n",
      "Iteration 152, loss = 0.81864710\n",
      "Iteration 153, loss = 0.81850729\n",
      "Iteration 154, loss = 0.81781494\n",
      "Iteration 155, loss = 0.81728426\n",
      "Iteration 156, loss = 0.81652436\n",
      "Iteration 157, loss = 0.81565712\n",
      "Iteration 158, loss = 0.81511431\n",
      "Iteration 159, loss = 0.81403620\n",
      "Iteration 160, loss = 0.81364107\n",
      "Iteration 161, loss = 0.81369926\n",
      "Iteration 162, loss = 0.81141523\n",
      "Iteration 163, loss = 0.81208745\n",
      "Iteration 164, loss = 0.81075686\n",
      "Iteration 165, loss = 0.81042583\n",
      "Iteration 166, loss = 0.80977942\n",
      "Iteration 167, loss = 0.80927406\n",
      "Iteration 168, loss = 0.80880025\n",
      "Iteration 169, loss = 0.80779047\n",
      "Iteration 170, loss = 0.80749954\n",
      "Iteration 171, loss = 0.80761089\n",
      "Iteration 172, loss = 0.80647248\n",
      "Iteration 173, loss = 0.80569558\n",
      "Iteration 174, loss = 0.80545369\n",
      "Iteration 175, loss = 0.80439431\n",
      "Iteration 176, loss = 0.80472606\n",
      "Iteration 177, loss = 0.80331034\n",
      "Iteration 178, loss = 0.80274879\n",
      "Iteration 179, loss = 0.80205965\n",
      "Iteration 180, loss = 0.80259739\n",
      "Iteration 181, loss = 0.80081806\n",
      "Iteration 182, loss = 0.80100984\n",
      "Iteration 183, loss = 0.80050791\n",
      "Iteration 184, loss = 0.79939760\n",
      "Iteration 185, loss = 0.79947199\n",
      "Iteration 186, loss = 0.79872627\n",
      "Iteration 187, loss = 0.79795834\n",
      "Iteration 188, loss = 0.79791898\n",
      "Iteration 189, loss = 0.79768596\n",
      "Iteration 190, loss = 0.79719744\n",
      "Iteration 191, loss = 0.79593598\n",
      "Iteration 192, loss = 0.79577686\n",
      "Iteration 193, loss = 0.79547553\n",
      "Iteration 194, loss = 0.79431154\n",
      "Iteration 195, loss = 0.79457253\n",
      "Iteration 196, loss = 0.79382944\n",
      "Iteration 197, loss = 0.79412299\n",
      "Iteration 198, loss = 0.79303428\n",
      "Iteration 199, loss = 0.79276652\n",
      "Iteration 200, loss = 0.79249283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
       "              warm_start=True)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = neural_net.predict(val_features)\n",
    "val_pred = np.argmax(val_pred, axis=1)\n",
    "val_pred = np.apply_along_axis(lambda x: x + 1, 0, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels.shape\n",
    "val_labels = val_labels.to_numpy()\n",
    "val_labels = np.argmax(val_labels, axis=1)\n",
    "val_labels = np.apply_along_axis(lambda x: x + 1, 0, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = neural_net.predict(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802967839694856"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(val_pred, val_labels)\n",
    "accuracy_score(train_pred, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rc\n",
    "sns.set_style(\"white\")\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(val_pred, val_labels)\n",
    "plt.xlabel(\"Predicted Value\", fontsize=\"medium\")\n",
    "plt.ylabel(\"Actual Value\", fontsize=\"medium\")\n",
    "plt.title(\"Neural Net Performance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"neural net box.png\", bbox_inches=\"tight\", dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(val_pred, val_labels)\n",
    "plt.xlabel(\"Predicted Value\", fontsize=\"medium\")\n",
    "plt.ylabel(\"Actual Value\", fontsize=\"medium\")\n",
    "plt.title(\"Neural Net Performance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visualization/neural net violin.png\", bbox_inches=\"tight\", dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
